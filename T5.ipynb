{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T5.ipynb","provenance":[{"file_id":"19XsAoWsyXRbB3LpVIoYkCqLwloSnmJsu","timestamp":1652451892244}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import files\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBbG-SIZ969D","executionInfo":{"status":"ok","timestamp":1652454344206,"user_tz":240,"elapsed":943,"user":{"displayName":"Leo Dupire","userId":"14507803081572357923"}},"outputId":"a4469a24-2242-4f66-cdea-5f5287385459"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UumWEhcf97be","executionInfo":{"status":"ok","timestamp":1652454356117,"user_tz":240,"elapsed":11915,"user":{"displayName":"Leo Dupire","userId":"14507803081572357923"}},"outputId":"e5fdc4fe-9eb4-4c09-b629-221b24e34e45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"]}]},{"cell_type":"code","source":["import torch\n","\n","def encode_data(dataset, tokenizer, max_seq_length=128):\n","    \"\"\"Featurizes the dataset into input IDs and attention masks for input into a\n","     transformer-style model.\n","  Args:\n","    dataset: A Pandas dataframe containing the data to be encoded.\n","    tokenizer: A transformers.PreTrainedTokenizerFast object that is used to\n","      tokenize the data.\n","    max_seq_length: Maximum sequence length to either pad or truncate every\n","      input example to.\n","  Returns:\n","    input_ids: A PyTorch.Tensor (with dimensions [len(dataset), max_seq_length])\n","      containing token IDs for the data.\n","    attention_mask: A PyTorch.Tensor (with dimensions [len(dataset), max_seq_length])\n","      containing attention masks for the data.\n","  \"\"\"\n","\n","    message = dataset['text'].apply(lambda x: 'true or false: ' + x).astype(str).values.tolist()\n","\n","    inputs = tokenizer(\n","      text= message,\n","      padding = 'max_length',\n","      truncation = True,\n","      max_length = max_seq_length,\n","      is_split_into_words = False,\n","      return_tensors='pt'\n","      )\n","    \n","    input_ids = torch.tensor(inputs[\"input_ids\"])\n","    attention_mask = torch.tensor(inputs[\"attention_mask\"])\n","\n","    return input_ids, attention_mask\n","\n","\n","def extract_labels(dataset, tokenizer):\n","    \"\"\"Converts labels into numerical labels.\n","  Args:\n","    dataset: A Pandas dataframe containing the labels in the column 'label'.\n","  Returns:\n","    labels: A list of integers corresponding to the labels for each example,\n","      where 1 is Misinformation, 0 is factual. \n","  \"\"\"\n","    CLASS_TOKENS = ['true','false']\n","\n","    target = list(dataset.label.apply(lambda x: CLASS_TOKENS[x]).astype(str).values)\n","\n","    target_encodings = tokenizer(\n","      text = target,\n","      padding = 'longest',\n","      truncation = False,\n","      is_split_into_words = False,\n","      return_tensors='pt')\n","\n","    labels = torch.tensor(target_encodings['input_ids'])\n","    decoder_attention_mask = torch.tensor(target_encodings['attention_mask'])\n","\n","    return labels, decoder_attention_mask\n"],"metadata":{"id":"9KyUge50-A2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","\n","class TGDataset(Dataset):\n","    \"\"\"\n","    A torch.utils.data.Dataset wrapper for the BoolQ dataset.\n","    \"\"\"\n","\n","    def __init__(self, dataframe, tokenizer, max_seq_length=256):\n","        \"\"\"\n","        Args:\n","          dataframe: A Pandas dataframe containing the data.\n","          tokenizer: A transformers.PreTrainedTokenizerFast object that is used to\n","            tokenize the data.\n","          max_seq_length: Maximum sequence length to either pad or truncate every\n","            input example to.\n","        \"\"\"\n","        self.encoded_data = encode_data(dataframe, tokenizer, max_seq_length)\n","\n","        self.label_list = extract_labels(dataframe, tokenizer)\n","\n","    def __len__(self):\n","        label, decoder_attention_mask = self.label_list\n","        return len(label)\n","\n","    def __getitem__(self, i):\n","        \"\"\"\n","        Returns:\n","          example: A dictionary containing the input_ids, attention_mask, and\n","            label for the i-th example, with the values being numeric tensors\n","            and the keys being 'input_ids', 'attention_mask', and 'labels'.\n","        \"\"\"\n","    \n","        input_ids, attention_mask = self.encoded_data\n","        label, decoder_attention_mask = self.label_list\n","        example = {\n","          'input_ids': input_ids[i],\n","          'attention_mask': attention_mask[i],\n","          'labels': label[i],\n","          'decoder_attention_mask': decoder_attention_mask[i]\n","        }\n","\n","        return example"],"metadata":{"id":"aMQYFHmYRtuI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(eval_pred):\n","    \"\"\"Computes accuracy, f1, precision, and recall from a \n","    transformers.trainer_utils.EvalPrediction object.\n","    \"\"\"\n","    from sklearn import metrics\n","\n","    labels = eval_pred.label_ids[:,0]\n","    preds = np.argmax(eval_pred.predictions[0], axis=2)[:,0]\n","    \n","\n","    accuracy = metrics.accuracy_score(y_true=labels, y_pred=preds)\n","    precision, recall, f1, _ = metrics.precision_recall_fscore_support(y_true=labels, y_pred=preds, average='macro')\n","\n","    result = {\n","        'accuracy': accuracy,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","    print(\"result \", result)\n","    return result\n","\n","def model_init():\n","    \"\"\"Returns an initialized model for use in a Hugging Face Trainer.\"\"\"\n","    from transformers import T5Config, T5ForConditionalGeneration\n","\n","    configuration = T5Config()\n","    model = T5ForConditionalGeneration(configuration).from_pretrained(\"t5-base\")\n","\n","    return model"],"metadata":{"id":"JCq0TFLs-Hp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-zDEZks90ti","executionInfo":{"status":"ok","timestamp":1652454384330,"user_tz":240,"elapsed":26743,"user":{"displayName":"Leo Dupire","userId":"14507803081572357923"}},"outputId":"96ad20b5-5957-462b-aae9-5740c75e6a0a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:169: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n","Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.19.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file https://huggingface.co/t5-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"]}],"source":["import pandas\n","import torch\n","from transformers import T5Tokenizer, Trainer, TrainingArguments\n","from transformers import T5ForConditionalGeneration\n","import sklearn\n","import numpy as np\n","from sklearn import metrics\n","from sklearn.metrics import f1_score\n","\n","train_df = pandas.read_csv(\"/content/drive/MyDrive/mumin-classifier/T5/T5_data/train_en.csv\")\n","val_df = pandas.read_csv(\"/content/drive/MyDrive/mumin-classifier/T5/T5_data/val_en.csv\")\n","test_df = pandas.read_csv(\"/content/drive/MyDrive/mumin-classifier/T5/T5_data/test_en.csv\")\n","\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n","train_data = TGDataset(train_df, tokenizer)\n","val_data = TGDataset(val_df, tokenizer)\n","test_data = TGDataset(test_df, tokenizer)\n","\n","\n","model_path = \"out_t5\"\n","trainingargs = TrainingArguments(\n","    output_dir=model_path,\n","    do_train=True,\n","    do_eval=True,\n","    disable_tqdm=False,\n","    learning_rate=1e-4,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    #logging_steps=500,\n","    logging_first_step=True,\n","    #save_steps=1000,\n","    evaluation_strategy = \"epoch\"\n","    )\n","\n","trainer = Trainer(\n","    args = trainingargs,\n","    tokenizer = tokenizer,\n","    train_dataset = train_data,\n","    eval_dataset = val_data,\n","    model_init = model_init,\n","    compute_metrics = compute_metrics\n","    ) "]},{"cell_type":"code","source":["print(\"STARTED TRAINING\")\n","trainer.train()\n","print(\"TRAINING DONE\")\n","\n","trainer.save_model()\n","print(\"MODEL SAVED\")   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tyou2Yjsdax2","executionInfo":{"status":"ok","timestamp":1652455113336,"user_tz":240,"elapsed":729018,"user":{"displayName":"Leo Dupire","userId":"14507803081572357923"}},"outputId":"96401fd7-adee-4ac5-e3f4-bc58d56948b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["STARTED TRAINING\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n","Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.19.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file https://huggingface.co/t5-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 3597\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1350\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1350/1350 11:59, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>11.447400</td>\n","      <td>0.099938</td>\n","      <td>0.956923</td>\n","      <td>0.522310</td>\n","      <td>0.517154</td>\n","      <td>0.546145</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.195000</td>\n","      <td>0.051287</td>\n","      <td>0.970769</td>\n","      <td>0.492584</td>\n","      <td>0.493740</td>\n","      <td>0.491433</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.072000</td>\n","      <td>0.084682</td>\n","      <td>0.958462</td>\n","      <td>0.523861</td>\n","      <td>0.518245</td>\n","      <td>0.546924</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 650\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9569230769230769, 'f1': 0.5223097112860893, 'precision': 0.5171540243196294, 'recall': 0.5461448598130841}\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to out_t5/checkpoint-500\n","Configuration saved in out_t5/checkpoint-500/config.json\n","Model weights saved in out_t5/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in out_t5/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in out_t5/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 650\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9707692307692307, 'f1': 0.49258391881342706, 'precision': 0.4937402190923318, 'recall': 0.4914330218068536}\n"]},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to out_t5/checkpoint-1000\n","Configuration saved in out_t5/checkpoint-1000/config.json\n","Model weights saved in out_t5/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in out_t5/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in out_t5/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 650\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9584615384615385, 'f1': 0.5238612007922081, 'precision': 0.5182451358921947, 'recall': 0.5469236760124611}\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to out_t5\n","Configuration saved in out_t5/config.json\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING DONE\n"]},{"output_type":"stream","name":"stderr","text":["Model weights saved in out_t5/pytorch_model.bin\n","tokenizer config file saved in out_t5/tokenizer_config.json\n","Special tokens file saved in out_t5/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["MODEL SAVED\n"]}]},{"cell_type":"code","source":["#Metrics\n","predictions = trainer.predict(test_data)\n","preds = np.argmax(predictions.predictions[0],axis=2)[:,0]\n","labels = predictions.label_ids[:,0]\n","\n","test_scores = f1_score(y_true=labels, y_pred=preds, average=None)\n","print(f'\\nMisinformation F1: {100 * test_scores[1]:.2f}%')\n","print(f'Factual F1: {100 * test_scores[0]:.2f}%')\n","print(f'macro-average F1: {100 * test_scores.mean():.4f}%\\n')\n","\n","report = sklearn.metrics.classification_report(y_pred=preds,y_true=labels)\n","\n","print(report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"ge_6Ug-F-i53","executionInfo":{"status":"ok","timestamp":1652455123821,"user_tz":240,"elapsed":10499,"user":{"displayName":"Leo Dupire","userId":"14507803081572357923"}},"outputId":"cdea62fc-140c-4122-f3e9-2451184c82ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 543\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [68/68 00:09]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9594843462246777, 'f1': 0.5665457184325109, 'precision': 0.7314471243042672, 'recall': 0.5435351596580004}\n","\n","Misinformation F1: 97.92%\n","Factual F1: 15.38%\n","macro-average F1: 56.6546%\n","\n","              precision    recall  f1-score   support\n","\n","        1176       0.50      0.09      0.15        22\n","        6136       0.96      1.00      0.98       521\n","\n","    accuracy                           0.96       543\n","   macro avg       0.73      0.54      0.57       543\n","weighted avg       0.94      0.96      0.95       543\n","\n"]}]},{"cell_type":"code","source":["langs = pandas.concat([val_df, test_df])\n","langs = langs.query(\"lang=='en' | lang=='pt' | lang=='es'| lang=='fr'| lang=='ar'\")\n","languages = ['en','pt','es','fr','ar']\n","f1 = []\n","randomf1 = []\n","for lang in languages:\n","  print(\"\\nLANG \", lang)\n","  lang_data = langs.query(f\"lang=='{lang}'\")\n","  test_data = TGDataset(lang_data, tokenizer)\n","  predictions = trainer.predict(test_data)\n","  predictions = trainer.predict(test_data)\n","  preds = np.argmax(predictions.predictions[0],axis=2)[:,0]\n","  labels = predictions.label_ids[:,0]\n","\n","  test_scores = f1_score(labels, preds, average=None)\n","\n","  print(f'\\nMisinformation F1: {100 * test_scores[1]:.2f}%')\n","  print(f'Factual F1: {100 * test_scores[0]:.2f}%')\n","  print(f'macro-average F1: {100 * test_scores.mean():.4f}%\\n')\n","  f1.append(100 * test_scores.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qAaNWsKC-1oW","executionInfo":{"status":"ok","timestamp":1652457563579,"user_tz":240,"elapsed":37297,"user":{"displayName":"Leo Dupire","userId":"14507803081572357923"}},"outputId":"10adfb88-f3c2-4460-a62c-5bca22afb4e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","LANG  en\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","***** Running Prediction *****\n","  Num examples = 680\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='680' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [68/68 40:49]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 680\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9485294117647058, 'f1': 0.538034511539432, 'precision': 0.5466867469879518, 'recall': 0.5328237707630203}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","***** Running Prediction *****\n","  Num examples = 182\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9485294117647058, 'f1': 0.538034511539432, 'precision': 0.5466867469879518, 'recall': 0.5328237707630203}\n","\n","Misinformation F1: 97.35%\n","Factual F1: 10.26%\n","macro-average F1: 53.8035%\n","\n","\n","LANG  pt\n"]},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 182\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.967032967032967, 'f1': 0.49162011173184356, 'precision': 0.4971751412429379, 'recall': 0.4861878453038674}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","***** Running Prediction *****\n","  Num examples = 111\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.967032967032967, 'f1': 0.49162011173184356, 'precision': 0.4971751412429379, 'recall': 0.4861878453038674}\n","\n","Misinformation F1: 98.32%\n","Factual F1: 0.00%\n","macro-average F1: 49.1620%\n","\n","\n","LANG  es\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","***** Running Prediction *****\n","  Num examples = 111\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9819819819819819, 'f1': 0.4954545454545454, 'precision': 0.49099099099099097, 'recall': 0.5}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","***** Running Prediction *****\n","  Num examples = 66\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9819819819819819, 'f1': 0.4954545454545454, 'precision': 0.49099099099099097, 'recall': 0.5}\n","\n","Misinformation F1: 99.09%\n","Factual F1: 0.00%\n","macro-average F1: 49.5455%\n","\n","\n","LANG  fr\n"]},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 66\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9393939393939394, 'f1': 0.484375, 'precision': 0.49206349206349204, 'recall': 0.47692307692307695}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","***** Running Prediction *****\n","  Num examples = 38\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9393939393939394, 'f1': 0.484375, 'precision': 0.49206349206349204, 'recall': 0.47692307692307695}\n","\n","Misinformation F1: 96.88%\n","Factual F1: 0.00%\n","macro-average F1: 48.4375%\n","\n","\n","LANG  ar\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","***** Running Prediction *****\n","  Num examples = 38\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["result  {'accuracy': 0.9736842105263158, 'f1': 0.4933333333333333, 'precision': 0.4868421052631579, 'recall': 0.5}\n","result  {'accuracy': 0.9736842105263158, 'f1': 0.4933333333333333, 'precision': 0.4868421052631579, 'recall': 0.5}\n","\n","Misinformation F1: 98.67%\n","Factual F1: 0.00%\n","macro-average F1: 49.3333%\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["f1"],"metadata":{"id":"Eupe7hZdK2v-","executionInfo":{"status":"ok","timestamp":1652457961734,"user_tz":240,"elapsed":194,"user":{"displayName":"Leo Dupire","userId":"14507803081572357923"}},"outputId":"3cd06d11-027d-4f47-e3ec-e6a80eec6703","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[53.80345115394321,\n"," 49.162011173184354,\n"," 49.54545454545454,\n"," 48.4375,\n"," 49.33333333333333]"]},"metadata":{},"execution_count":40}]}]}