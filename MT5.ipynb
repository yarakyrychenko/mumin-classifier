{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBbG-SIZ969D",
        "outputId": "0d8aecfb-8577-4ea2-9b6a-81d6f91cc724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UumWEhcf97be",
        "outputId": "607a3ce8-7537-47fe-bc3b-0db2c0e25c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9KyUge50-A2b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def encode_data(dataset, tokenizer, max_seq_length=128):\n",
        "    \"\"\"Featurizes the dataset into input IDs and attention masks for input into a\n",
        "     transformer-style model.\n",
        "  Args:\n",
        "    dataset: A Pandas dataframe containing the data to be encoded.\n",
        "    tokenizer: A transformers.PreTrainedTokenizerFast object that is used to\n",
        "      tokenize the data.\n",
        "    max_seq_length: Maximum sequence length to either pad or truncate every\n",
        "      input example to.\n",
        "  Returns:\n",
        "    input_ids: A PyTorch.Tensor (with dimensions [len(dataset), max_seq_length])\n",
        "      containing token IDs for the data.\n",
        "    attention_mask: A PyTorch.Tensor (with dimensions [len(dataset), max_seq_length])\n",
        "      containing attention masks for the data.\n",
        "  \"\"\"\n",
        "\n",
        "    message = dataset['text'].apply(lambda x: 'true or false: ' + x).astype(str).values.tolist()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "      text= message,\n",
        "      padding = 'max_length',\n",
        "      truncation = True,\n",
        "      max_length = max_seq_length,\n",
        "      is_split_into_words = False,\n",
        "      return_tensors='pt'\n",
        "      )\n",
        "    \n",
        "    input_ids = torch.tensor(inputs[\"input_ids\"])\n",
        "    attention_mask = torch.tensor(inputs[\"attention_mask\"])\n",
        "\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "\n",
        "def extract_labels(dataset, tokenizer):\n",
        "    \"\"\"Converts labels into numerical labels.\n",
        "  Args:\n",
        "    dataset: A Pandas dataframe containing the labels in the column 'label'.\n",
        "  Returns:\n",
        "    labels: A list of integers corresponding to the labels for each example,\n",
        "      where 1 is Misinformation, 0 is factual. \n",
        "  \"\"\"\n",
        "    CLASS_TOKENS = ['true','false']\n",
        "\n",
        "    target = list(dataset.label.apply(lambda x: CLASS_TOKENS[x]).astype(str).values)\n",
        "\n",
        "    target_encodings = tokenizer(\n",
        "      text = target,\n",
        "      padding = 'longest',\n",
        "      truncation = False,\n",
        "      is_split_into_words = False\n",
        "     # return_tensors='pt'\n",
        "      )\n",
        "\n",
        "    labels = torch.tensor(target_encodings['input_ids'])\n",
        "    decoder_attention_mask = torch.tensor(target_encodings['attention_mask'])\n",
        "\n",
        "    return labels, decoder_attention_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aMQYFHmYRtuI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class TGDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A torch.utils.data.Dataset wrapper for the BoolQ dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_seq_length=256):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          dataframe: A Pandas dataframe containing the data.\n",
        "          tokenizer: A transformers.PreTrainedTokenizerFast object that is used to\n",
        "            tokenize the data.\n",
        "          max_seq_length: Maximum sequence length to either pad or truncate every\n",
        "            input example to.\n",
        "        \"\"\"\n",
        "        self.encoded_data = encode_data(dataframe, tokenizer, max_seq_length)\n",
        "\n",
        "        self.label_list = extract_labels(dataframe, tokenizer)\n",
        "\n",
        "    def __len__(self):\n",
        "        label, decoder_attention_mask = self.label_list\n",
        "        return len(label)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          example: A dictionary containing the input_ids, attention_mask, and\n",
        "            label for the i-th example, with the values being numeric tensors\n",
        "            and the keys being 'input_ids', 'attention_mask', and 'labels'.\n",
        "        \"\"\"\n",
        "    \n",
        "        input_ids, attention_mask = self.encoded_data\n",
        "        label, decoder_attention_mask = self.label_list\n",
        "        example = {\n",
        "          'input_ids': input_ids[i],\n",
        "          'attention_mask': attention_mask[i],\n",
        "          'labels': label[i],\n",
        "          'decoder_attention_mask': decoder_attention_mask[i]\n",
        "        }\n",
        "\n",
        "        return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JCq0TFLs-Hp1"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Computes accuracy, f1, precision, and recall from a \n",
        "    transformers.trainer_utils.EvalPrediction object.\n",
        "    \"\"\"\n",
        "    from sklearn import metrics\n",
        "\n",
        "    labels = eval_pred.label_ids[:,0]\n",
        "    preds = np.argmax(eval_pred.predictions[0], axis=2)[:,0]\n",
        "    \n",
        "\n",
        "    accuracy = metrics.accuracy_score(y_true=labels, y_pred=preds)\n",
        "    precision, recall, f1, _ = metrics.precision_recall_fscore_support(y_true=labels, y_pred=preds, average='macro')\n",
        "\n",
        "    result = {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "    print(\"result \", result)\n",
        "    return result\n",
        "\n",
        "def model_init():\n",
        "    \"\"\"Returns an initialized model for use in a Hugging Face Trainer.\"\"\"\n",
        "    from transformers import MT5Config, MT5ForConditionalGeneration\n",
        "\n",
        "    configuration = MT5Config()\n",
        "    model = MT5ForConditionalGeneration(configuration).from_pretrained(\"google/mt5-small\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yYooKOQiGJM5"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-zDEZks90ti"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import torch\n",
        "from transformers import MT5Tokenizer, Trainer, TrainingArguments\n",
        "from transformers import MT5ForConditionalGeneration\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "train_df = pandas.read_csv(\"/content/drive/MyDrive/mumin-classifier/data/train_m.csv\")\n",
        "val_df = pandas.read_csv(\"/content/drive/MyDrive/mumin-classifier/data/val_m.csv\")\n",
        "test_df = pandas.read_csv(\"/content/drive/MyDrive/mumin-classifier/data/test_m.csv\")\n",
        "\n",
        "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-base\")\n",
        "train_data = TGDataset(train_df, tokenizer)\n",
        "val_data = TGDataset(val_df, tokenizer)\n",
        "test_data = TGDataset(test_df, tokenizer)\n",
        "\n",
        "\n",
        "model_path = \"out_mt5\"\n",
        "trainingargs = TrainingArguments(\n",
        "    output_dir=model_path,\n",
        "    do_train=True,\n",
        "    do_eval=False,\n",
        "    disable_tqdm=False,\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size = 4,\n",
        "    per_device_eval_batch_size = 4,\n",
        "    #logging_steps=500,\n",
        "    #logging_first_step=True,\n",
        "    save_steps=5000\n",
        "    #evaluation_strategy = \"epoch\"\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    args = trainingargs,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_data,\n",
        "    eval_dataset = val_data,\n",
        "    model_init = model_init,\n",
        "    compute_metrics = compute_metrics\n",
        "    ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tyou2Yjsdax2",
        "outputId": "3e51e2da-e15f-4680-b38b-dfa55d2dd0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTED TRAINING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "Model config MT5Config {\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.19.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n",
            "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3597\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2700\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2700' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2700/2700 10:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>7.927500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.756300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.675500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.589700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to out_mt5\n",
            "Configuration saved in out_mt5/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DONE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in out_mt5/pytorch_model.bin\n",
            "tokenizer config file saved in out_mt5/tokenizer_config.json\n",
            "Special tokens file saved in out_mt5/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL SAVED\n"
          ]
        }
      ],
      "source": [
        "print(\"STARTED TRAINING\")\n",
        "trainer.train()\n",
        "print(\"TRAINING DONE\")\n",
        "\n",
        "trainer.save_model()\n",
        "print(\"MODEL SAVED\")   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ge_6Ug-F-i53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "17603486-fd40-4d16-ab93-bb069f52098a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 543\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [136/136 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result  {'accuracy': 0.9594843462246777, 'f1': 0.48966165413533835, 'precision': 0.47974217311233885, 'recall': 0.5}\n",
            "\n",
            "Misinformation F1: 0.00%\n",
            "Factual F1: 97.93%\n",
            "macro-average F1: 48.9662%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         259       0.96      1.00      0.98       521\n",
            "        6274       0.00      0.00      0.00        22\n",
            "\n",
            "    accuracy                           0.96       543\n",
            "   macro avg       0.48      0.50      0.49       543\n",
            "weighted avg       0.92      0.96      0.94       543\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#Metrics\n",
        "predictions = trainer.predict(test_data)\n",
        "preds = np.argmax(predictions.predictions[0],axis=2)[:,0]\n",
        "labels = predictions.label_ids[:,0]\n",
        "\n",
        "test_scores = f1_score(y_true=labels, y_pred=preds, average=None)\n",
        "print(f'\\nMisinformation F1: {100 * test_scores[1]:.2f}%')\n",
        "print(f'Factual F1: {100 * test_scores[0]:.2f}%')\n",
        "print(f'macro-average F1: {100 * test_scores.mean():.4f}%\\n')\n",
        "\n",
        "report = sklearn.metrics.classification_report(y_pred=preds,y_true=labels)\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rbtYjg5exNLq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ca47527c-3527-4003-d495-ce4c34ff56e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-89325cf4ab64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlangs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlangs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlangs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lang=='en' | lang=='pt' | lang=='es'| lang=='fr'| lang=='ar'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'es'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrandomf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "langs = pd.concat([val_df, test_df])\n",
        "langs = langs.query(\"lang=='en' | lang=='pt' | lang=='es'| lang=='fr'| lang=='ar'\")\n",
        "languages = ['en','pt','es','fr','ar']\n",
        "f1 = []\n",
        "randomf1 = []\n",
        "for lang in languages:\n",
        "  print(\"\\nLANG \", lang)\n",
        "  lang_data = langs.query(f\"lang=='{lang}'\")\n",
        "  test_data = tg_data.TGDataset(lang_data, tokenizer)\n",
        "  predictions = trainer.predict(test_data)\n",
        "  predictions = trainer.predict(test_data)\n",
        "  preds = np.argmax(predictions.predictions[0],axis=2)[:,0]\n",
        "  labels = predictions.label_ids[:,0]\n",
        "\n",
        "  test_scores = f1_score(labels, preds, average=None)\n",
        "\n",
        "  print(f'\\nMisinformation F1: {100 * test_scores[1]:.2f}%')\n",
        "  print(f'Factual F1: {100 * test_scores[0]:.2f}%')\n",
        "  print(f'macro-average F1: {100 * test_scores.mean():.4f}%\\n')\n",
        "  f1.append(100 * test_scores.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vnLO6IsXa0ZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d12927a-5865-4f10-d8d7-69e37bd5329a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LANG  en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 680\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='407' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [136/136 41:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result  {'accuracy': 0.9661764705882353, 'f1': 0.4913986537023186, 'precision': 0.48308823529411765, 'recall': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 182\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Misinformation F1: 0.00%\n",
            "Factual F1: 98.28%\n",
            "macro-average F1: 49.1399%\n",
            "\n",
            "\n",
            "LANG  pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result  {'accuracy': 0.9945054945054945, 'f1': 0.4986225895316804, 'precision': 0.49725274725274726, 'recall': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 111\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Misinformation F1: 0.00%\n",
            "Factual F1: 99.72%\n",
            "macro-average F1: 49.8623%\n",
            "\n",
            "\n",
            "LANG  es\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 66\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result  {'accuracy': 0.9819819819819819, 'f1': 0.4954545454545454, 'precision': 0.49099099099099097, 'recall': 0.5}\n",
            "\n",
            "Misinformation F1: 0.00%\n",
            "Factual F1: 99.09%\n",
            "macro-average F1: 49.5455%\n",
            "\n",
            "\n",
            "LANG  fr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 38\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result  {'accuracy': 0.9848484848484849, 'f1': 0.4961832061068702, 'precision': 0.49242424242424243, 'recall': 0.5}\n",
            "\n",
            "Misinformation F1: 0.00%\n",
            "Factual F1: 99.24%\n",
            "macro-average F1: 49.6183%\n",
            "\n",
            "\n",
            "LANG  ar\n",
            "result  {'accuracy': 0.9736842105263158, 'f1': 0.4933333333333333, 'precision': 0.4868421052631579, 'recall': 0.5}\n",
            "\n",
            "Misinformation F1: 0.00%\n",
            "Factual F1: 98.67%\n",
            "macro-average F1: 49.3333%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pandas.read_csv(\"/content/test_m.csv\")\n",
        "val_df = pandas.read_csv(\"/content/val_m.csv\")\n",
        "test_df = pandas.read_csv(\"/content/test_m.csv\")\n",
        "\n",
        "langs = pd.concat([val_df, test_df])\n",
        "langs = langs.query(\"lang=='en' | lang=='pt' | lang=='es'| lang=='fr'| lang=='ar'\")\n",
        "languages = ['en','pt','es','fr','ar']\n",
        "f1 = []\n",
        "randomf1 = []\n",
        "for lang in languages:\n",
        "  print(\"\\nLANG \", lang)\n",
        "  lang_data = langs.query(f\"lang=='{lang}'\")\n",
        "  test_data = TGDataset(lang_data, tokenizer)\n",
        "  predictions = trainer.predict(test_data)\n",
        "  preds = np.argmax(predictions.predictions[0],axis=2)[:,0]\n",
        "  labels = predictions.label_ids[:,0]\n",
        "\n",
        "  test_scores = f1_score(labels, preds, average=None)\n",
        "\n",
        "  print(f'\\nMisinformation F1: {100 * test_scores[1]:.2f}%')\n",
        "  print(f'Factual F1: {100 * test_scores[0]:.2f}%')\n",
        "  print(f'macro-average F1: {100 * test_scores.mean():.4f}%\\n')\n",
        "  f1.append(100 * test_scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1"
      ],
      "metadata": {
        "id": "NaZw9E83LG-o",
        "outputId": "92b6770a-89d4-434d-8f20-3e12e43ef54e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[49.13986537023186,\n",
              " 49.862258953168045,\n",
              " 49.54545454545454,\n",
              " 49.61832061068702,\n",
              " 49.33333333333333]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MT5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}